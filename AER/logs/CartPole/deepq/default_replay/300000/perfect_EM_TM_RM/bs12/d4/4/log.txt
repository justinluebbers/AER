Logging to ./AER/logs/CartPole/deepq/default_replay/300000/perfect_EM_TM_RM/bs12/d4/4/
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 100      |
| mean 100 episode reward | 22.1     |
| steps                   | 2.18e+03 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 200      |
| mean 100 episode reward | 26.4     |
| steps                   | 4.83e+03 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 300      |
| mean 100 episode reward | 26.7     |
| steps                   | 7.5e+03  |
--------------------------------------
Saving model due to mean reward increase: None -> 27.600000381469727
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 400      |
| mean 100 episode reward | 26.7     |
| steps                   | 1.02e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 500      |
| mean 100 episode reward | 31.2     |
| steps                   | 1.33e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 600      |
| mean 100 episode reward | 48.6     |
| steps                   | 1.81e+04 |
--------------------------------------
Saving model due to mean reward increase: 27.600000381469727 -> 45.0
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 700      |
| mean 100 episode reward | 40.7     |
| steps                   | 2.22e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 800      |
| mean 100 episode reward | 53.6     |
| steps                   | 2.76e+04 |
--------------------------------------
Saving model due to mean reward increase: 45.0 -> 62.599998474121094
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 900      |
| mean 100 episode reward | 90.2     |
| steps                   | 3.66e+04 |
--------------------------------------
Saving model due to mean reward increase: 62.599998474121094 -> 99.0999984741211
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1e+03    |
| mean 100 episode reward | 130      |
| steps                   | 4.96e+04 |
--------------------------------------
Saving model due to mean reward increase: 99.0999984741211 -> 126.30000305175781
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.1e+03  |
| mean 100 episode reward | 115      |
| steps                   | 6.11e+04 |
--------------------------------------
Saving model due to mean reward increase: 126.30000305175781 -> 131.1999969482422
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.2e+03  |
| mean 100 episode reward | 111      |
| steps                   | 7.21e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.3e+03  |
| mean 100 episode reward | 57.7     |
| steps                   | 7.79e+04 |
--------------------------------------
Saving model due to mean reward increase: 131.1999969482422 -> 165.8000030517578
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.4e+03  |
| mean 100 episode reward | 190      |
| steps                   | 9.69e+04 |
--------------------------------------
Saving model due to mean reward increase: 165.8000030517578 -> 181.10000610351562
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.5e+03  |
| mean 100 episode reward | 143      |
| steps                   | 1.11e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.6e+03  |
| mean 100 episode reward | 137      |
| steps                   | 1.25e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.7e+03  |
| mean 100 episode reward | 106      |
| steps                   | 1.36e+05 |
--------------------------------------
Saving model due to mean reward increase: 181.10000610351562 -> 181.6999969482422
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.8e+03  |
| mean 100 episode reward | 192      |
| steps                   | 1.55e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.9e+03  |
| mean 100 episode reward | 139      |
| steps                   | 1.69e+05 |
--------------------------------------
Saving model due to mean reward increase: 181.6999969482422 -> 184.39999389648438
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2e+03    |
| mean 100 episode reward | 190      |
| steps                   | 1.88e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.1e+03  |
| mean 100 episode reward | 161      |
| steps                   | 2.04e+05 |
--------------------------------------
Saving model due to mean reward increase: 184.39999389648438 -> 188.1999969482422
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.2e+03  |
| mean 100 episode reward | 192      |
| steps                   | 2.23e+05 |
--------------------------------------
Saving model due to mean reward increase: 188.1999969482422 -> 190.60000610351562
Saving model due to mean reward increase: 190.60000610351562 -> 195.1999969482422
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.3e+03  |
| mean 100 episode reward | 194      |
| steps                   | 2.42e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.4e+03  |
| mean 100 episode reward | 183      |
| steps                   | 2.61e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.5e+03  |
| mean 100 episode reward | 176      |
| steps                   | 2.78e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.6e+03  |
| mean 100 episode reward | 187      |
| steps                   | 2.97e+05 |
--------------------------------------
Restored model with mean reward: 195.1999969482422
