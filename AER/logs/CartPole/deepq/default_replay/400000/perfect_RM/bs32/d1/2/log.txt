Logging to ./AER/logs/CartPole/deepq/default_replay/400000/perfect_RM/bs32/d1/2/
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 100      |
| mean 100 episode reward | 22.6     |
| steps                   | 2.24e+03 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 200      |
| mean 100 episode reward | 24.8     |
| steps                   | 4.72e+03 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 300      |
| mean 100 episode reward | 28.2     |
| steps                   | 7.54e+03 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 400      |
| mean 100 episode reward | 22.2     |
| steps                   | 9.76e+03 |
--------------------------------------
Saving model due to mean reward increase: None -> 21.299999237060547
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 500      |
| mean 100 episode reward | 22.3     |
| steps                   | 1.2e+04  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 600      |
| mean 100 episode reward | 22.8     |
| steps                   | 1.43e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 700      |
| mean 100 episode reward | 28.1     |
| steps                   | 1.71e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 800      |
| mean 100 episode reward | 25.6     |
| steps                   | 1.96e+04 |
--------------------------------------
Saving model due to mean reward increase: 21.299999237060547 -> 27.0
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 900      |
| mean 100 episode reward | 30.8     |
| steps                   | 2.27e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 1e+03    |
| mean 100 episode reward | 59.5     |
| steps                   | 2.87e+04 |
--------------------------------------
Saving model due to mean reward increase: 27.0 -> 65.0
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 1.1e+03  |
| mean 100 episode reward | 48.2     |
| steps                   | 3.35e+04 |
--------------------------------------
Saving model due to mean reward increase: 65.0 -> 76.9000015258789
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.2e+03  |
| mean 100 episode reward | 93.2     |
| steps                   | 4.28e+04 |
--------------------------------------
Saving model due to mean reward increase: 76.9000015258789 -> 105.5999984741211
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.3e+03  |
| mean 100 episode reward | 120      |
| steps                   | 5.48e+04 |
--------------------------------------
Saving model due to mean reward increase: 105.5999984741211 -> 131.10000610351562
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.4e+03  |
| mean 100 episode reward | 128      |
| steps                   | 6.76e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.5e+03  |
| mean 100 episode reward | 106      |
| steps                   | 7.82e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.6e+03  |
| mean 100 episode reward | 134      |
| steps                   | 9.16e+04 |
--------------------------------------
Saving model due to mean reward increase: 131.10000610351562 -> 153.1999969482422
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.7e+03  |
| mean 100 episode reward | 130      |
| steps                   | 1.05e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.8e+03  |
| mean 100 episode reward | 104      |
| steps                   | 1.15e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.9e+03  |
| mean 100 episode reward | 107      |
| steps                   | 1.26e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2e+03    |
| mean 100 episode reward | 118      |
| steps                   | 1.37e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.1e+03  |
| mean 100 episode reward | 104      |
| steps                   | 1.48e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.2e+03  |
| mean 100 episode reward | 99.5     |
| steps                   | 1.58e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.3e+03  |
| mean 100 episode reward | 97.4     |
| steps                   | 1.67e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.4e+03  |
| mean 100 episode reward | 36.9     |
| steps                   | 1.71e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.5e+03  |
| mean 100 episode reward | 65       |
| steps                   | 1.78e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.6e+03  |
| mean 100 episode reward | 119      |
| steps                   | 1.9e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.7e+03  |
| mean 100 episode reward | 22       |
| steps                   | 1.92e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.8e+03  |
| mean 100 episode reward | 71.6     |
| steps                   | 1.99e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.9e+03  |
| mean 100 episode reward | 137      |
| steps                   | 2.13e+05 |
--------------------------------------
Saving model due to mean reward increase: 153.1999969482422 -> 160.3000030517578
Saving model due to mean reward increase: 160.3000030517578 -> 178.0
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 3e+03    |
| mean 100 episode reward | 178      |
| steps                   | 2.3e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 3.1e+03  |
| mean 100 episode reward | 106      |
| steps                   | 2.41e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 3.2e+03  |
| mean 100 episode reward | 38.1     |
| steps                   | 2.45e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 3.3e+03  |
| mean 100 episode reward | 56.8     |
| steps                   | 2.5e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 3.4e+03  |
| mean 100 episode reward | 102      |
| steps                   | 2.61e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 3.5e+03  |
| mean 100 episode reward | 123      |
| steps                   | 2.73e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 3.6e+03  |
| mean 100 episode reward | 116      |
| steps                   | 2.85e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 3.7e+03  |
| mean 100 episode reward | 119      |
| steps                   | 2.96e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 3.8e+03  |
| mean 100 episode reward | 129      |
| steps                   | 3.09e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 3.9e+03  |
| mean 100 episode reward | 109      |
| steps                   | 3.2e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 4e+03    |
| mean 100 episode reward | 111      |
| steps                   | 3.31e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 4.1e+03  |
| mean 100 episode reward | 64.5     |
| steps                   | 3.38e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 4.2e+03  |
| mean 100 episode reward | 74.6     |
| steps                   | 3.45e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 4.3e+03  |
| mean 100 episode reward | 85.3     |
| steps                   | 3.54e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 4.4e+03  |
| mean 100 episode reward | 123      |
| steps                   | 3.66e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 4.5e+03  |
| mean 100 episode reward | 11.8     |
| steps                   | 3.67e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 4.6e+03  |
| mean 100 episode reward | 42.7     |
| steps                   | 3.72e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 4.7e+03  |
| mean 100 episode reward | 72       |
| steps                   | 3.79e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 4.8e+03  |
| mean 100 episode reward | 12.1     |
| steps                   | 3.8e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 4.9e+03  |
| mean 100 episode reward | 12.3     |
| steps                   | 3.81e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 5e+03    |
| mean 100 episode reward | 29.7     |
| steps                   | 3.84e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 5.1e+03  |
| mean 100 episode reward | 34.8     |
| steps                   | 3.88e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 5.2e+03  |
| mean 100 episode reward | 53.2     |
| steps                   | 3.93e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 5.3e+03  |
| mean 100 episode reward | 59.4     |
| steps                   | 3.99e+05 |
--------------------------------------
Restored model with mean reward: 178.0
