Logging to ./AER/logs/CartPole/deepq/default_replay/400000/default/bs48/4/
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 100      |
| mean 100 episode reward | 23.5     |
| steps                   | 2.33e+03 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 200      |
| mean 100 episode reward | 24.1     |
| steps                   | 4.74e+03 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 300      |
| mean 100 episode reward | 28.6     |
| steps                   | 7.6e+03  |
--------------------------------------
Saving model due to mean reward increase: None -> 27.5
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 400      |
| mean 100 episode reward | 27.3     |
| steps                   | 1.03e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 500      |
| mean 100 episode reward | 27.6     |
| steps                   | 1.31e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 600      |
| mean 100 episode reward | 26.8     |
| steps                   | 1.58e+04 |
--------------------------------------
Saving model due to mean reward increase: 27.5 -> 45.20000076293945
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 700      |
| mean 100 episode reward | 45.2     |
| steps                   | 2.03e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 800      |
| mean 100 episode reward | 25.8     |
| steps                   | 2.29e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 900      |
| mean 100 episode reward | 39.2     |
| steps                   | 2.68e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 1e+03    |
| mean 100 episode reward | 42.4     |
| steps                   | 3.1e+04  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 1.1e+03  |
| mean 100 episode reward | 52.6     |
| steps                   | 3.63e+04 |
--------------------------------------
Saving model due to mean reward increase: 45.20000076293945 -> 68.5
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.2e+03  |
| mean 100 episode reward | 109      |
| steps                   | 4.71e+04 |
--------------------------------------
Saving model due to mean reward increase: 68.5 -> 111.19999694824219
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.3e+03  |
| mean 100 episode reward | 81.2     |
| steps                   | 5.53e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.4e+03  |
| mean 100 episode reward | 143      |
| steps                   | 6.95e+04 |
--------------------------------------
Saving model due to mean reward increase: 111.19999694824219 -> 141.8000030517578
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.5e+03  |
| mean 100 episode reward | 146      |
| steps                   | 8.41e+04 |
--------------------------------------
Saving model due to mean reward increase: 141.8000030517578 -> 168.60000610351562
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.6e+03  |
| mean 100 episode reward | 162      |
| steps                   | 1e+05    |
--------------------------------------
Saving model due to mean reward increase: 168.60000610351562 -> 177.0
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.7e+03  |
| mean 100 episode reward | 157      |
| steps                   | 1.16e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.8e+03  |
| mean 100 episode reward | 159      |
| steps                   | 1.32e+05 |
--------------------------------------
Saving model due to mean reward increase: 177.0 -> 190.8000030517578
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.9e+03  |
| mean 100 episode reward | 158      |
| steps                   | 1.48e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2e+03    |
| mean 100 episode reward | 128      |
| steps                   | 1.61e+05 |
--------------------------------------
Saving model due to mean reward increase: 190.8000030517578 -> 194.8000030517578
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.1e+03  |
| mean 100 episode reward | 190      |
| steps                   | 1.8e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.2e+03  |
| mean 100 episode reward | 195      |
| steps                   | 1.99e+05 |
--------------------------------------
Saving model due to mean reward increase: 194.8000030517578 -> 195.89999389648438
Saving model due to mean reward increase: 195.89999389648438 -> 196.89999389648438
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.3e+03  |
| mean 100 episode reward | 198      |
| steps                   | 2.19e+05 |
--------------------------------------
Saving model due to mean reward increase: 196.89999389648438 -> 197.8000030517578
Saving model due to mean reward increase: 197.8000030517578 -> 199.6999969482422
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.4e+03  |
| mean 100 episode reward | 195      |
| steps                   | 2.38e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.5e+03  |
| mean 100 episode reward | 157      |
| steps                   | 2.54e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.6e+03  |
| mean 100 episode reward | 198      |
| steps                   | 2.74e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.7e+03  |
| mean 100 episode reward | 185      |
| steps                   | 2.92e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.8e+03  |
| mean 100 episode reward | 188      |
| steps                   | 3.11e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 2.9e+03  |
| mean 100 episode reward | 199      |
| steps                   | 3.31e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 3e+03    |
| mean 100 episode reward | 165      |
| steps                   | 3.48e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 3.1e+03  |
| mean 100 episode reward | 189      |
| steps                   | 3.66e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 3.2e+03  |
| mean 100 episode reward | 188      |
| steps                   | 3.85e+05 |
--------------------------------------
Restored model with mean reward: 199.6999969482422
