Logging to ./AER/logs/Acrobot/deepq/default_replay/300000/bs2/d32/2/
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 100      |
| mean 100 episode reward | -421     |
| steps                   | 4.17e+04 |
--------------------------------------
Saving model due to mean reward increase: None -> -415.0
Saving model due to mean reward increase: -415.0 -> -400.79998779296875
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 200      |
| mean 100 episode reward | -407     |
| steps                   | 8.25e+04 |
--------------------------------------
Saving model due to mean reward increase: -400.79998779296875 -> -385.79998779296875
Saving model due to mean reward increase: -385.79998779296875 -> -370.70001220703125
Saving model due to mean reward increase: -370.70001220703125 -> -356.1000061035156
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 300      |
| mean 100 episode reward | -336     |
| steps                   | 1.16e+05 |
--------------------------------------
Saving model due to mean reward increase: -356.1000061035156 -> -348.70001220703125
Saving model due to mean reward increase: -348.70001220703125 -> -334.3999938964844
Saving model due to mean reward increase: -334.3999938964844 -> -323.0
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 400      |
| mean 100 episode reward | -314     |
| steps                   | 1.48e+05 |
--------------------------------------
Saving model due to mean reward increase: -323.0 -> -309.3999938964844
Saving model due to mean reward increase: -309.3999938964844 -> -236.8000030517578
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 500      |
| mean 100 episode reward | -169     |
| steps                   | 1.65e+05 |
--------------------------------------
Saving model due to mean reward increase: -236.8000030517578 -> -147.89999389648438
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 600      |
| mean 100 episode reward | -137     |
| steps                   | 1.78e+05 |
--------------------------------------
Saving model due to mean reward increase: -147.89999389648438 -> -130.6999969482422
Saving model due to mean reward increase: -130.6999969482422 -> -120.5999984741211
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 700      |
| mean 100 episode reward | -120     |
| steps                   | 1.91e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 800      |
| mean 100 episode reward | -118     |
| steps                   | 2.03e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 900      |
| mean 100 episode reward | -120     |
| steps                   | 2.15e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1e+03    |
| mean 100 episode reward | -137     |
| steps                   | 2.28e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.1e+03  |
| mean 100 episode reward | -131     |
| steps                   | 2.42e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.2e+03  |
| mean 100 episode reward | -169     |
| steps                   | 2.59e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.3e+03  |
| mean 100 episode reward | -173     |
| steps                   | 2.76e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.4e+03  |
| mean 100 episode reward | -152     |
| steps                   | 2.91e+05 |
--------------------------------------
Restored model with mean reward: -120.5999984741211
