Logging to ./AER/logs/Acrobot/deepq/default_replay/300000/bs2/d32/0/
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 100      |
| mean 100 episode reward | -376     |
| steps                   | 3.73e+04 |
--------------------------------------
Saving model due to mean reward increase: None -> -375.79998779296875
Saving model due to mean reward increase: -375.79998779296875 -> -361.79998779296875
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 200      |
| mean 100 episode reward | -431     |
| steps                   | 8.05e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 300      |
| mean 100 episode reward | -373     |
| steps                   | 1.18e+05 |
--------------------------------------
Saving model due to mean reward increase: -361.79998779296875 -> -354.6000061035156
Saving model due to mean reward increase: -354.6000061035156 -> -329.3999938964844
Saving model due to mean reward increase: -329.3999938964844 -> -311.3999938964844
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 400      |
| mean 100 episode reward | -296     |
| steps                   | 1.48e+05 |
--------------------------------------
Saving model due to mean reward increase: -311.3999938964844 -> -308.79998779296875
Saving model due to mean reward increase: -308.79998779296875 -> -280.20001220703125
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 500      |
| mean 100 episode reward | -243     |
| steps                   | 1.72e+05 |
--------------------------------------
Saving model due to mean reward increase: -280.20001220703125 -> -138.8000030517578
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 600      |
| mean 100 episode reward | -127     |
| steps                   | 1.85e+05 |
--------------------------------------
Saving model due to mean reward increase: -138.8000030517578 -> -124.0
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 700      |
| mean 100 episode reward | -114     |
| steps                   | 1.96e+05 |
--------------------------------------
Saving model due to mean reward increase: -124.0 -> -117.0999984741211
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 800      |
| mean 100 episode reward | -126     |
| steps                   | 2.09e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 900      |
| mean 100 episode reward | -122     |
| steps                   | 2.21e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1e+03    |
| mean 100 episode reward | -139     |
| steps                   | 2.35e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.1e+03  |
| mean 100 episode reward | -151     |
| steps                   | 2.5e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.2e+03  |
| mean 100 episode reward | -165     |
| steps                   | 2.67e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.3e+03  |
| mean 100 episode reward | -157     |
| steps                   | 2.83e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.4e+03  |
| mean 100 episode reward | -168     |
| steps                   | 3e+05    |
--------------------------------------
Restored model with mean reward: -117.0999984741211
