Logging to ./AER/logs/Acrobot/deepq/default_replay/300000/bs2/d32/1/
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 100      |
| mean 100 episode reward | -374     |
| steps                   | 3.71e+04 |
--------------------------------------
Saving model due to mean reward increase: None -> -367.8999938964844
Saving model due to mean reward increase: -367.8999938964844 -> -360.6000061035156
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 200      |
| mean 100 episode reward | -412     |
| steps                   | 7.84e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 300      |
| mean 100 episode reward | -346     |
| steps                   | 1.13e+05 |
--------------------------------------
Saving model due to mean reward increase: -360.6000061035156 -> -250.89999389648438
Saving model due to mean reward increase: -250.89999389648438 -> -211.0
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 400      |
| mean 100 episode reward | -204     |
| steps                   | 1.34e+05 |
--------------------------------------
Saving model due to mean reward increase: -211.0 -> -205.5
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 500      |
| mean 100 episode reward | -160     |
| steps                   | 1.5e+05  |
--------------------------------------
Saving model due to mean reward increase: -205.5 -> -157.0
Saving model due to mean reward increase: -157.0 -> -137.3000030517578
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 600      |
| mean 100 episode reward | -127     |
| steps                   | 1.62e+05 |
--------------------------------------
Saving model due to mean reward increase: -137.3000030517578 -> -128.5
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 700      |
| mean 100 episode reward | -122     |
| steps                   | 1.75e+05 |
--------------------------------------
Saving model due to mean reward increase: -128.5 -> -116.30000305175781
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 800      |
| mean 100 episode reward | -117     |
| steps                   | 1.86e+05 |
--------------------------------------
Saving model due to mean reward increase: -116.30000305175781 -> -115.30000305175781
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 900      |
| mean 100 episode reward | -116     |
| steps                   | 1.98e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1e+03    |
| mean 100 episode reward | -118     |
| steps                   | 2.1e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.1e+03  |
| mean 100 episode reward | -127     |
| steps                   | 2.23e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.2e+03  |
| mean 100 episode reward | -125     |
| steps                   | 2.36e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.3e+03  |
| mean 100 episode reward | -142     |
| steps                   | 2.5e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.4e+03  |
| mean 100 episode reward | -156     |
| steps                   | 2.65e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.5e+03  |
| mean 100 episode reward | -154     |
| steps                   | 2.81e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.6e+03  |
| mean 100 episode reward | -168     |
| steps                   | 2.98e+05 |
--------------------------------------
Restored model with mean reward: -115.30000305175781
