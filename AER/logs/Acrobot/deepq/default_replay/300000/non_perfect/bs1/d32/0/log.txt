Logging to ./AER/logs/Acrobot/deepq/default_replay/300000/bs1/d32/0/
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 100      |
| mean 100 episode reward | -329     |
| steps                   | 3.26e+04 |
--------------------------------------
Saving model due to mean reward increase: None -> -266.6000061035156
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 200      |
| mean 100 episode reward | -339     |
| steps                   | 6.65e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 300      |
| mean 100 episode reward | -386     |
| steps                   | 1.05e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 400      |
| mean 100 episode reward | -296     |
| steps                   | 1.35e+05 |
--------------------------------------
Saving model due to mean reward increase: -266.6000061035156 -> -217.39999389648438
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 500      |
| mean 100 episode reward | -131     |
| steps                   | 1.48e+05 |
--------------------------------------
Saving model due to mean reward increase: -217.39999389648438 -> -125.0
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 600      |
| mean 100 episode reward | -135     |
| steps                   | 1.62e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 700      |
| mean 100 episode reward | -173     |
| steps                   | 1.79e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 800      |
| mean 100 episode reward | -118     |
| steps                   | 1.91e+05 |
--------------------------------------
Saving model due to mean reward increase: -125.0 -> -114.0
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 900      |
| mean 100 episode reward | -115     |
| steps                   | 2.03e+05 |
--------------------------------------
Saving model due to mean reward increase: -114.0 -> -110.19999694824219
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1e+03    |
| mean 100 episode reward | -117     |
| steps                   | 2.14e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.1e+03  |
| mean 100 episode reward | -118     |
| steps                   | 2.26e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.2e+03  |
| mean 100 episode reward | -138     |
| steps                   | 2.4e+05  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.3e+03  |
| mean 100 episode reward | -141     |
| steps                   | 2.54e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.4e+03  |
| mean 100 episode reward | -143     |
| steps                   | 2.69e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.5e+03  |
| mean 100 episode reward | -144     |
| steps                   | 2.83e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 1.6e+03  |
| mean 100 episode reward | -146     |
| steps                   | 2.98e+05 |
--------------------------------------
Restored model with mean reward: -110.19999694824219
