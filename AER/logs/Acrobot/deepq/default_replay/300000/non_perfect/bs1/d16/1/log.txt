Logging to ./AER/logs/Acrobot/deepq/default_replay/300000/bs1/d16/1/
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 100      |
| mean 100 episode reward | -366     |
| steps                   | 3.63e+04 |
--------------------------------------
Saving model due to mean reward increase: None -> -365.1000061035156
Saving model due to mean reward increase: -365.1000061035156 -> -364.8999938964844
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 200      |
| mean 100 episode reward | -473     |
| steps                   | 8.36e+04 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 300      |
| mean 100 episode reward | -489     |
| steps                   | 1.33e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 400      |
| mean 100 episode reward | -482     |
| steps                   | 1.81e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 500      |
| mean 100 episode reward | -459     |
| steps                   | 2.27e+05 |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 600      |
| mean 100 episode reward | -364     |
| steps                   | 2.63e+05 |
--------------------------------------
Saving model due to mean reward increase: -364.8999938964844 -> -286.0
Saving model due to mean reward increase: -286.0 -> -171.5
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 700      |
| mean 100 episode reward | -171     |
| steps                   | 2.8e+05  |
--------------------------------------
Saving model due to mean reward increase: -171.5 -> -162.0
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 800      |
| mean 100 episode reward | -160     |
| steps                   | 2.96e+05 |
--------------------------------------
Restored model with mean reward: -162.0
